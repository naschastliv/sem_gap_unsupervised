{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная обучение без учителя\n",
    "\n",
    "Лабораторная состоит из гайда по работе с задачами машинного обучения без учителя (unsupervised learning) на Python и трёх обязательных заданий:\n",
    "* [Задание 1](#Задание-1.) - понижение размерности с помощью t-SNE;\n",
    "* [Задание 2](#Задание-2.) - кластеризация с фильтрацией выбросов с помощью DBSCAN;\n",
    "* [Задание 3](#Задание-3.) - кластеризация вершин графа генов _Mus musculus_ с помощью MCL.\n",
    "\n",
    "Сначала рекомендуется ознакомиться с гайдом, после чего выполнять задания."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Используемые модули\n",
    "\n",
    "Обновим пакетный менеджер pip, чтобы корректно уставить необходимые модули:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# При необходимости добавляйте опцию --user\n",
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Установим необходимые модули:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# При необходимости добавляйте опцию --user\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подключим модули, которые пригодятся в мини-лабораторной."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import random\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "\n",
    "from scipy.sparse import find\n",
    "\n",
    "import networkx as nx\n",
    "import markov_clustering as mc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Понижение размерности\n",
    "\n",
    "Одна из задач обучения без учителя (unsupervised learning) - понижение размерности.\n",
    "\n",
    "Напомним, что идея задачи понижения размерности состоит в переходе к небольшому числу показательных (информативных) признаков, принимающих много значений - с такими признаками работать проще.\n",
    "\n",
    "Воспользуемся методом t-SNE для понижения размерности для данных \"wine\" (набор данных доступен в библиотеке scikit-learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Прочитаем данные\n",
    "x_all, y_all = load_iris(return_X_y=True)\n",
    "# Поделим на тренировочную и тестовую выборки\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_all, y_all, test_size=0.2, random_state=123)\n",
    "\n",
    "print(f'Размеры выборок: тренировочная - {x_train.shape[0]}, тестовая - {x_test.shape[0]}')\n",
    "print(f'Кол-во признаков: {x_train.shape[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим классификатор, основанный на _машине опорных векторов_ (support vector machine, SVM).\n",
    "\n",
    "Метод SVM ищет параметры гиперплоскости (или гиперповерхности), которая разделяет пространство признаков данных на области, каждая область соответствует своему классу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sv_clf = SVC(kernel='linear', random_state=123)\n",
    "sv_clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценим качество полученной модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = sv_clf.predict(x_test)\n",
    "print('Accuracy score = {:.3f}'.format(accuracy_score(y_test, predictions)))\n",
    "print('F1 score = {:.3f}'.format(f1_score(y_test, predictions, average='macro')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Воспользуемся t-SNE в качестве предобработки данных\n",
    "\n",
    "_Примечание:_ особенность метода t-SNE и его реализации в scikit-learn в том, что этот метод нельзя применять к новым данным, которые могут появиться на стадии предсказания обученной модели. Появление новых данных может серьёзно изменить отображение, построенное с помощью t-SNE, что является серьёзным ограничением применимости этого метода. В связи с этим, отображение t-SNE следует строить сразу и для тренировочных, и для тестовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2, init='random', random_state=123, learning_rate='auto')\n",
    "# Так как строим отображение сразу и для тренировочных, и для тестовых данных, надо запомнить, какие из данных тренировочные\n",
    "train_len = x_train.shape[0]\n",
    "x_all_transformed = tsne.fit_transform(np.vstack([x_train, x_test]))\n",
    "x_train_transformed = x_all_transformed[:train_len, :]  # Вытаскиваем признаки для тренировочных данных\n",
    "x_test_transformed = x_all_transformed[train_len:, :]  # Остальные данные - тестовые\n",
    "print(f'Кол-во признаков после предобработки: {x_train_transformed.shape[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Визуализация данных после предобработки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_tsne_result(x_train_new, x_test_new, y_train, y_test):\n",
    "    fig, ax = plt.subplots(ncols=2, figsize=(15, 5))\n",
    "    ax[0].scatter(x_train_new[:,0], x_train_new[:,1], c=y_train)\n",
    "    ax[0].set_title('Train')\n",
    "    \n",
    "    ax[1].scatter(x_test_new[:,0], x_test_new[:,1], c=y_test)\n",
    "    ax[1].set_title('Test')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "show_tsne_result(x_train_transformed, x_test_transformed, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим SVM-классификатор с линейным ядром и посмотрим, как улучшилось качество"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sv_clf = SVC(kernel='linear', random_state=123)\n",
    "sv_clf.fit(x_train_transformed, y_train)\n",
    "predictions = sv_clf.predict(x_test_transformed)\n",
    "print('Accuracy score = {:.3f}'.format(accuracy_score(y_test, predictions)))\n",
    "print('F1 score = {:.3f}'.format(f1_score(y_test, predictions, average='macro')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Задание 1.\n",
    "\n",
    "Подберите параметры `TSNE` так, чтобы SVM-классификатор с линейным ядром, обученный на предобработанных данных, давал качество по **каждой** из метрик `accuracy` и `f1` **не ниже** `0.98`. При этом параметр `n_components` оставьте равным `2`.\n",
    "\n",
    "Когда подберёте параметры, скопируйте создание переменной `tsne` (вызов конструктора `TSNE` с подобранными параметрами и присваивание результата переменной `tsne`) в соответствующее задание курса на Stepik.\n",
    "\n",
    "Менять можно **только** параметры `t-SNE`, менять гиперпараметры SVM-классификатора **запрещается**.\n",
    "\n",
    "_Подсказки_:\n",
    "1. Наиболее важный параметр в методе t-SNE - `perplexity`;\n",
    "2. SVM с линейным ядром идеально работает, когда данные линейно разделимы - то есть, когда для каждого класса есть прямая (в нашем случае), отделяющая этот класс от остальных классов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Поменяйте параметры в TSNE.\n",
    "# Когда подберёте подходящие параметры и проверите результат, скопируйте весь код этой ячейки в поле ввода\n",
    "# ответа в соответствующем задании курса на Stepik.\n",
    "tsne = TSNE(\n",
    "    n_components=2,  # но кол-во размерностей оставьте равным 2\n",
    "    init='random',\n",
    "    random_state=123,\n",
    "    perplexity=30.0,\n",
    "    learning_rate='auto',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для вычисления метрик качества и просмотра результатов выполните код ниже:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_len = x_train.shape[0]\n",
    "x_all_transformed = tsne.fit_transform(np.vstack([x_train, x_test]))\n",
    "x_train_transformed = x_all_transformed[:train_len, :]\n",
    "x_test_transformed = x_all_transformed[train_len:, :]\n",
    "\n",
    "show_tsne_result(x_train_transformed, x_test_transformed, y_train, y_test)\n",
    "\n",
    "sv_clf = SVC(kernel='linear', random_state=123)\n",
    "sv_clf.fit(x_train_transformed, y_train)\n",
    "predictions = sv_clf.predict(x_test_transformed)\n",
    "final_accuracy, final_f1 = accuracy_score(y_test, predictions), f1_score(y_test, predictions, average='macro')\n",
    "print('Accuracy score = {:.3f}'.format(final_accuracy))\n",
    "print('F1 score = {:.3f}'.format(final_f1))\n",
    "if final_accuracy >= 0.98 and final_f1 >= 0.98:\n",
    "    print('Требуемое качество достигнуто')\n",
    "else:\n",
    "    print('Требуемое качество не достигнуто')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Кластеризация\n",
    "\n",
    "### K-Means\n",
    "\n",
    "На практике случается, что надо объединить данные в группы, при этом известно количество групп. Такую задачу можно решить с помощью метода кластеризации _K-Means_ (или K-средних).\n",
    "\n",
    "Метод пытается найти такие \"центры\" кластеров, чтобы минимизировать СКО внутри кластеров.\n",
    "\n",
    "Особенности метода:\n",
    "* Требуется задать кол-во кластеров\n",
    "* Требуется задать начальное положение всех центров\n",
    "\n",
    "#### Пример\n",
    "\n",
    "Сгенерируем данные, посмотрим на них"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_blobs, y_blobs = make_blobs(n_samples=100, centers=3, n_features=2, random_state=1234)  # Лучше не менять random_state\n",
    "\n",
    "plt.scatter(x_blobs[:,0], x_blobs[:,1], c=y_blobs)\n",
    "plt.title('Clusters')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По картинке видно, что данные образуют 3 группы.\n",
    "\n",
    "Воспользуемся методом K-means, чтобы разделить данные на группы, не пользуясь информацией о метках\n",
    "\n",
    "_Замечание_: обычно начальное положение центров кластеров задаются случайным образом, как и в случае метода `KMeans` из библиотеки scikit-learn, который использован далее"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_clustering = KMeans(n_clusters=3, random_state=123)\n",
    "kmeans_clustering.fit(x_blobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, как выполнена кластеризация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x_blobs[:,0], x_blobs[:,1], c=kmeans_clustering.labels_)\n",
    "plt.title('Clustering with K-Means (K = 3)')\n",
    "\n",
    "cluster_centers = kmeans_clustering.cluster_centers_\n",
    "\n",
    "# Красными точками отметим центры кластеров\n",
    "plt.plot(cluster_centers[:,0], cluster_centers[:,1], 'ro', markersize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, что будет, если с помощью параметра `n_clusters` задать не 3, а 4 кластера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_clustering = KMeans(n_clusters=4, random_state=123)\n",
    "kmeans_clustering.fit(x_blobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x_blobs[:,0], x_blobs[:,1], c=kmeans_clustering.labels_)\n",
    "plt.title('Clustering with K-Means (K = 4)')\n",
    "\n",
    "cluster_centers = kmeans_clustering.cluster_centers_\n",
    "\n",
    "# Красными точками отметим центры кластеров\n",
    "plt.plot(cluster_centers[:,0], cluster_centers[:,1], 'ro', markersize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель `K-means` имеет свои особенности, из-за которых она применима в задачах, где известно кол-во кластеров, и эти кластеры можно описывать шарами (это заложено в принцип обучения модели).\n",
    "\n",
    "Если \"контекст\", в котором ставится задача кластеризации, подразумевает, что кластерам могут соответствовать области более сложной формы, или неизвестно кол-во кластеров, следует пользоваться другими методами.\n",
    "\n",
    "### DBSCAN\n",
    "\n",
    "Рассмотрим подробнее метод кластеризации _DBSCAN_.\n",
    "\n",
    "Особенности этого метода:\n",
    "* Кластерами считаются такие облака из точек, где точки находятся _достаточно близко_ друг к другу - можно находить плотные кластеры более сложной формы, чем простые шары\n",
    "* Точки, у которых \"нет соседей\", можно считать выбросами\n",
    "\n",
    "#### Пример\n",
    "\n",
    "Сгенерируем данные в виде прямоугольной области и \"кольца\" около этой области"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "\n",
    "# Данные для первого кластера - \"квадрат\"\n",
    "cluster_1 = np.random.uniform(-2, 2, (300, 2))\n",
    "\n",
    "# Данные для второго кластера - \"кольцо\".\n",
    "# Для достижения \"формы кольца\" семплируем точки из равномерного распределения\n",
    "# в прямоугольнике в полярных координатах, потом переводим полярные координаты\n",
    "# в декартовы по известным формулам\n",
    "cluster_2_phi = np.random.uniform(-np.pi, np.pi, 350)\n",
    "cluster_2_r = np.random.uniform(4, 5, 350)\n",
    "cluster_2_x, cluster_2_y = cluster_2_r * np.cos(cluster_2_phi), cluster_2_r * np.sin(cluster_2_phi)\n",
    "cluster_2 = np.vstack([cluster_2_x, cluster_2_y]).transpose(1, 0)\n",
    "\n",
    "# Объединяем данные в единый массив\n",
    "clusters = np.vstack([cluster_1, cluster_2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(clusters[:,0], clusters[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим кластеризацию с помощью `KMeans` и `DBSCAN`.\n",
    "\n",
    "Ожидаем, что KMeans не сможет отличить кольцо от прямоугольника, а DBSCAN сможет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=2, random_state=123).fit(clusters)\n",
    "dbscan = DBSCAN(eps=1, min_samples=10).fit(clusters)\n",
    "\n",
    "fig, ax = plt.subplots(ncols=2, figsize=(15, 5))\n",
    "\n",
    "for i, (method, name) in enumerate(zip((kmeans, dbscan), (\"KMeans\", \"DBSCAN\"))):\n",
    "    ax[i].scatter(clusters[:,0], clusters[:,1], c=method.labels_)\n",
    "    ax[i].set_title(name)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Задание 2.\n",
    "\n",
    "Ниже заново будет создан массив входных данных похожим образом, но с добавлением \"выбросов\".\n",
    "\n",
    "Произведите кластеризацию таким образом, чтобы \"выбросы\" были зафиксированы, но при этом кластеры \"не распадались\" на более мелкие компоненты. Следует подбирать **следующие параметры** конструктора `DBSCAN`: `eps`, `min_samples`.\n",
    "\n",
    "Требуется найти такие параметры, при которых данные разбиваются на кластеры в соответствии с тем, как они сгенерированы (кластеров в итоге оказывается 2, и объекты в них соответствуют исходному разбиению объектов на кластеры), при этом \"выбросы\" верно определяются (выбросов определяется столько, сколько их было добавлено в исходные данные; никакой объект, не являвшийся выбросом при генерации, не помечается выбросом в результате работы алгоритма DBSCAN).\n",
    "\n",
    "Скопируйте инициализацию переменной `dbscan` результатом вызова конструктора `DBSCAN` с подобранными параметрами в поле ввода ответа в соответствующем задании курса на Stepik.\n",
    "\n",
    "_Подсказки_:\n",
    "1. Если кластер распадается на множество кластеров, можно увеличивать eps (макс. расстояние между объектами кластера);\n",
    "2. Если кластер вбирает в себя много лишних точек, можно уменьшать eps;\n",
    "3. Чтобы несколько стоящих рядом выбросов не объединялись в целый кластер, можно увеличивать min_samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Поменяйте параметры в DBSCAN.\n",
    "# Когда подберёте параметры и проверите результат, скопируйте содержимое этой ячейки\n",
    "# в поле ввода ответа в соответствующем задании курса на Stepik\n",
    "dbscan = DBSCAN(\n",
    "    eps=1,\n",
    "    min_samples=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для просмотра результатов и их самопроверки выполните код ниже:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)  # Для воспроизводимости\n",
    "\n",
    "# Данные для первого кластера - \"квадрат\"\n",
    "cluster_1_size = 300\n",
    "cluster_1 = np.random.uniform(-2, 2, (cluster_1_size, 2))\n",
    "\n",
    "# Данные для второго кластера - \"кольцо\"\n",
    "cluster_2_size = 800\n",
    "cluster_2_phi = np.random.uniform(-np.pi, np.pi, cluster_2_size)\n",
    "cluster_2_r = np.random.uniform(4, 5, cluster_2_size)\n",
    "cluster_2_x, cluster_2_y = cluster_2_r * np.cos(cluster_2_phi), cluster_2_r * np.sin(cluster_2_phi)\n",
    "cluster_2 = np.vstack([cluster_2_x, cluster_2_y]).transpose(1, 0)\n",
    "\n",
    "# Данные для \"выбросов\". Так как хотим, чтобы \"выбросы\" не попадали\n",
    "# в исходные кластеры, генерируем их в двух кольцах, которые не\n",
    "# пересекаются с областями исходных кластеров\n",
    "outliers_size = 40\n",
    "cluster_outliers_phi = np.random.uniform(-np.pi, np.pi + 0.1, 40)\n",
    "cluster_outliers_r = np.hstack([np.random.uniform(3.15, 3.4, 20), np.random.uniform(5.5, 6, 20)])\n",
    "outliers_x, outliers_y = cluster_outliers_r * np.cos(cluster_outliers_phi), cluster_outliers_r * np.sin(cluster_outliers_phi)\n",
    "outliers = np.vstack([outliers_x, outliers_y]).transpose(1, 0)\n",
    "\n",
    "# Объединяем всё в один массив\n",
    "clusters = np.vstack([cluster_1, cluster_2, outliers])\n",
    "\n",
    "# Проводим кластеризацию\n",
    "dbscan = dbscan.fit(clusters)\n",
    "\n",
    "# Создаём метки кластеров, -1 соответствует выбросам.\n",
    "# Так как данные не перемешаны, первые cluster_1_size элементов относятся к первому кластеру,\n",
    "# следующие cluster_2_size элементов - ко второму.\n",
    "clusters_labels = [0] * cluster_1_size + [1] * cluster_2_size + [-1] * outliers_size\n",
    "\n",
    "\n",
    "# Проверяем результат кластеризации. Выбросы помечены -1\n",
    "outliers_len_ans = len(clusters[dbscan.labels_ == -1])\n",
    "clustering_labels = set(dbscan.labels_)\n",
    "clustering_labels.remove(-1)\n",
    "if len(clustering_labels) != 2:\n",
    "    print(\"Получено неверное кол-во кластеров (требуется 2 получить кластера и выбросы)\")\n",
    "elif outliers_len_ans > outliers.shape[0]:\n",
    "    print(f\"Среди выбросов есть объекты, не являющиеся выбросами\")\n",
    "elif outliers_len_ans < outliers.shape[0]:\n",
    "    print(f\"Выделены не все выбросы\")\n",
    "else:\n",
    "    # Проверим, совпадают ли кластеры с классами\n",
    "    clusters_match = True\n",
    "    for label in clustering_labels:\n",
    "        clusters_match = clusters_match and len(set(np.array(clusters_labels)[dbscan.labels_ == label])) == 1\n",
    "    if clusters_match:\n",
    "        print(\"Задание выполнено верно\")\n",
    "    else:\n",
    "        print(\"Выбросы отобраны верно, но полученные кластеры не соответствуют исходным данным\")\n",
    "        \n",
    "\n",
    "# Отрисовка результатов, 2 графика: исходное распределение и кластеризация с отбрасыванием \"выбросов\"\n",
    "fig, ax = plt.subplots(ncols=2, figsize=(15, 5))\n",
    "\n",
    "ax[0].scatter(clusters[:,0], clusters[:,1], c=clusters_labels)\n",
    "ax[0].set_title('All')\n",
    "\n",
    "# На втором графике отрисовываем кластеры, выкидывая выбросы\n",
    "clusters_no_outliers = clusters[dbscan.labels_ != -1,:]\n",
    "ax[1].scatter(clusters_no_outliers[:,0], clusters_no_outliers[:,1], c=dbscan.labels_[dbscan.labels_ != -1])\n",
    "ax[1].set_title('No outliers')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### MCL\n",
    "\n",
    "Еще один интересный алгоритм кластеризации - _MCL algorithm - Markov Cluster Algorithm_ на основе графов.\n",
    "\n",
    "Метод опирается на следующие утверджения:\n",
    "* Расстояние между узлами графа, относящимися к одному кластеру, меньше, чем расстояниме между узлами, относящимися к различным кластерам\n",
    "* При случайном обходе графа, прежде чем покинуть кластер, будут посещены многие из его вершин\n",
    "* Края между кластерами вероятнее всего находятся на кратчайших путях\n",
    "\n",
    "Особенности метода:\n",
    "\n",
    "* Может работать с взвешенными и невзвешенными графами\n",
    "* Может находить кластеры произвольной формы\n",
    "* Не умеет находить перекрывающиеся кластеры\n",
    "* Кластеры могут быть разного размера\n",
    "\n",
    "Подробнее можно прочитать тут: https://micans.org/mcl/\n",
    "\n",
    "Для того, чтобы воспользоваться алгоритмом, дополнительно установим библиотеку `markov-clustering`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Пример\n",
    "\n",
    "Посмотрим, как алгоритм будет работать на модельных данных. Сгенерируем случайный граф с помощью библиотеки `networkx`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# задаем нужное количество вершин\n",
    "nodesnum = 50\n",
    "\n",
    "# генерируем граф\n",
    "graph = nx.random_geometric_graph(nodesnum, radius = 0.3)\n",
    "\n",
    "# получаем матрицу смежности из сгенерированного графа\n",
    "matrix = nx.to_scipy_sparse_array(graph)\n",
    "\n",
    "# получаем расположение узлов сгенерированного графа\n",
    "positions = nx.spring_layout(graph)\n",
    "\n",
    "#нарисуем получившийся граф\n",
    "nx.draw(graph, pos = positions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применим марковский алгоритм кластеризации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# получаем результат кластеризации\n",
    "result = mc.run_mcl(matrix)\n",
    "\n",
    "# выделяем получившиеся кластеры\n",
    "clusters = mc.get_clusters(result)\n",
    "\n",
    "# отрисовываем граф с результатами кластеризации\n",
    "mc.draw_graph(matrix, clusters, pos = positions, with_labels = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Одной из наиболее популярных метрик оценки качества кластеризации на графах является __модулярность__.\n",
    "\n",
    "Модулярность представляет собой меру \"неслучайности\" полученных кластеров.\n",
    "\n",
    "Пусть $k_i$ - степень вершины $i$,  \n",
    "$m$ - число ребер в графе,  \n",
    "$A$ - матрица смежности, содержащая веса ребер,  \n",
    "$c_i$ - кластер, к которому относится вершина $i$,  \n",
    "$\\delta(i,j) = 1$ при $c_i=c_j$, иначе $0$.  \n",
    "Допустим, мы перемещаем ребра, сохраняя распределение степеней. Тогда грубая оценка вероятности того, что $i$ и $j$ будут соединены, равняется: $\\cfrac{k_ik_j}{2m}$.\n",
    "\n",
    "Тогда __модулярность__ - мера \"неслучайнсости\" - рассчитывается следующим образом:\n",
    "$$Q = \\cfrac{1}{2m}\\sum_{i, j}\\left[A_{i, j} - \\cfrac{k_ik_j}{2m}\\right]\\delta(c_i, c_j)$$\n",
    "\n",
    "Чем выше значение величины модулярности, тем лучше качество кластеризации. Модулярность лежит в интервале от $-1$ до $1$.\n",
    "\n",
    "Посчитаем модулярность нашего варианта кластеризации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = mc.modularity(matrix = result, clusters = clusters)\n",
    "print('Modularity score = {:.3f}'.format(Q))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим [данные](https://www.omicsdi.org/dataset/geo/GSE10246) об эксперссии генов мышей. Был построен граф генов _Mus musculus_, где вершинами являются сами гены, а взвешенные ребра показывают отношение их коэкспрессии друг к другу.   \n",
    "Загрузим получившийся граф и посмотрим на него:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# считываем датасет\n",
    "G = pd.read_csv(os.path.join(\"data\", \"task3.csv\"), sep=\";\", header=None)\n",
    "\n",
    "# создаем граф\n",
    "graph = nx.Graph()\n",
    "\n",
    "for i in range(len(G)):\n",
    "    graph.add_edge(G[0][i], G[1][i], weight = G[2][i])\n",
    "\n",
    "# получаем матрицу смежности для данного графа\n",
    "matr = nx.to_scipy_sparse_array(graph)\n",
    "\n",
    "# получаем расположение узлов графа генов\n",
    "p = nx.spring_layout(graph, seed=123)\n",
    " \n",
    "# отрисовываем граф\n",
    "nx.draw(graph, pos=p, node_size=50, edge_color=\"silver\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Задание 3.\n",
    "\n",
    "Проведите кластеризацию с помощью марковского алгоритма так, чтобы модулярность оказалась **не ниже** `0.796`.\n",
    "\n",
    "Для этого изменяйте параметры алгоритма - функции `run_mcl`.\n",
    "Результат кластеризации окажется в переменной `res` - этот результат надо передать в Stepik, для этого:\n",
    "* Выполните последнюю ячейку с кодом, в которой происходит сериализация `res` в строку и печать этой строки;\n",
    "* Скопируйте вывод той ячейки и вставьте в поле ввода ответа в соответствующем задании курса на Stepik.\n",
    "\n",
    "_Наиболее важные параметры:_\n",
    "* `expansion > 1`, целое - \"расширение\" матрицы - то есть степень, в которую будет возводиться матрица смежности\n",
    "* `inflation > 1`, вещественное - \"инфляция\" матрицы - то есть степень, в которую будет возведен каждый элемент матрицы\n",
    "\n",
    "Другие параметры:\n",
    "* `loop_value >=0` - значение, присваемое в матрице смежности для переходов из вершины в саму себя\n",
    "* `iterations > 0` - количество итераций алгоритма. Если будет достигнута сходимость, итераций может быть меньше указанных\n",
    "* `pruning_treshold >= 0` - если значение в матрице становится меньше данного, оно заменяется на 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = mc.run_mcl(\n",
    "    matr,\n",
    "    # Эти параметры можно менять\n",
    "    expansion=2,\n",
    "    inflation=2,\n",
    "    loop_value=1,\n",
    "    iterations=100,\n",
    "    pruning_threshold=0.001,\n",
    ")\n",
    "\n",
    "# выделяем получившиеся кластеры\n",
    "clusters = mc.get_clusters(res)\n",
    "\n",
    "# отрисовываем граф с результатами кластеризации\n",
    "mc.draw_graph(graph, clusters, pos=p, with_labels = False, node_size=30, edge_color=\"silver\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вычисляем модулярность\n",
    "Q = mc.modularity(matrix = res, clusters = clusters)\n",
    "print('Modularity score = {:.5f}'.format(Q))\n",
    "print('Требуемое качество достигнуто' if Q >= 0.796 else 'Требуемое качество не достигнуто')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Когда требуемое качество кластеризации достигнуто, выполните ячейку ниже, её результат (вывод) скопируйте и вставьте в поле ввода ответа в соответствующем задании курса на Stepik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res - итоговая матрица с разбиением на кластеры, она хранится\n",
    "# в разреженном виде\n",
    "\n",
    "# Получаем ненулевые элементы из разреженной матрицы\n",
    "I, J, V = find(res)\n",
    "\n",
    "# Хотим передать разреженную матрицу в проверяющую систему,\n",
    "# для этого сериализуем её в строку\n",
    "serialized_res = \"\"\n",
    "for i, j, value in zip(I, J, V):\n",
    "    serialized_res += f\"{i}:{j}:{value}|\"\n",
    "\n",
    "print(f'res = \"{serialized_res}\"')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
